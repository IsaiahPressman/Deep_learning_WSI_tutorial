{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ### TODO: Outline image here###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "\n",
    "1. [Libraries & Environment](#Libraries-&-Environment)\n",
    "1. [Data Preprocessing](#Data-Preprocessing)\n",
    "    1. Tiling\n",
    "    1. Filtering out background tiles\n",
    "    1. Macenko normalization\n",
    "    1. Tumor detection\n",
    "1. [Training Deep Learning Models](#Training-Deep-Learning-Models)\n",
    "    1. Data splitting\n",
    "    1. Model and data loading\n",
    "    1. Common hardware bottlenecks\n",
    "    1. Real-time performance monitoring\n",
    "    1. Misc.\n",
    "1. [Evaluating Performance](#Evaluating-Performance)\n",
    "    1. Patient-level vs. tile-level evaluation\n",
    "    1. AUROC vs. accuracy\n",
    "    1. On improving performance\n",
    "1. [Visualizing Results](#Visualizing-Results)\n",
    "    1. TODO: outline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries & Environment\n",
    "\n",
    "The base environment that I use can be installed using the create_conda_env.sh bash script.\n",
    "\n",
    "NB: As of June 2021, when installing OpenSlide on Linux, it will not work correctly with some image types due to a broken dependency. (I've noticed this problem for .mrxs images in particular) In order to repair this issue, you can install version 0.40.0 of the pixman library. (Installed automatically in the create_conda_env.sh script) If you notice the slide images look like like the image below, or throw an error when you view them, try this solution.\n",
    "\n",
    "TODO: insert image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from openslide import OpenSlide, OpenSlideError\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import re\n",
    "from scipy import ndimage\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "import time\n",
    "import tqdm\n",
    "import traceback\n",
    "import warnings\n",
    "\n",
    "# Pytorch imports\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Custom imports\n",
    "from library.MacenkoNormalizer import MacenkoNormalizer\n",
    "from library.model_utils import load_saved_model_for_inference\n",
    "\n",
    "# A couple constants are defined here\n",
    "# MICRONS_PER_TILE defines the tile edge length used when breaking WSIs into smaller images\n",
    "MICRONS_PER_TILE = 256.\n",
    "# DEVICE determines which GPU (or CPU) the deep learning code will be run on\n",
    "# DEVICE = torch.device('cpu')\n",
    "DEVICE = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "In order to prepare the WSI images for deep learning training and inference, a number of preprocessing steps must be applied:\n",
    "\n",
    "1. Images are broken into many small tiles (usually 256x256 microns)\n",
    "1. Tiles are filtered to exclude non-tissue background regions\n",
    "1. Tiles are Macenko-normalized\n",
    "1. Tiles are filtered to exclude non-tumorous tissue regions\n",
    "\n",
    "These steps are laid out in example code below. However, when applying this pipeline at scale, the implementation should include multiprocessing and/or CuPy (for Macenko normalization) as these additions provide enormous speedups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring WSIs/MSIMUT/TCGA-5M-AATE-01Z-00-DX1.483FFD2F-61A1-477E-8F94-157383803FC7.svs, as it has already been processed.\n",
      "Ignoring WSIs/MSIMUT/TCGA-5M-AAT6-01Z-00-DX1.8834C952-14E3-4491-8156-52FC917BB014.svs, as it has already been processed.\n",
      "Ignoring WSIs/MSS/TCGA-4N-A93T-01Z-00-DX1.82E240B1-22C3-46E3-891F-0DCE35C43F8B.svs, as it has already been processed.\n",
      "Ignoring WSIs/MSS/TCGA-3L-AA1B-01Z-00-DX1.8923A151-A690-40B7-9E5A-FCBEDFC2394F.svs, as it has already been processed.\n",
      "Masking and normalizing 0 tiles from 0 whole slide images.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Macenko Normalizer\n",
    "reference_img = np.array(Image.open('library/macenko_reference_img.png').convert('RGB'))\n",
    "normalizer = MacenkoNormalizer()\n",
    "normalizer.fit(reference_img)\n",
    "\n",
    "# Find all WSIs and check for errors opening the file or finding the microns-per-pixel values \n",
    "base_path = Path('WSIs')\n",
    "base_save_path = Path('tiled_WSIs')\n",
    "wsi_paths = base_path.rglob('*.svs')\n",
    "save_paths = []\n",
    "wsi_paths_to_normalize = []\n",
    "total_num_tiles = 0\n",
    "for wsi_path in wsi_paths:\n",
    "    try:\n",
    "        with OpenSlide(str(wsi_path)) as wsi:\n",
    "            sub_path = Path(str(wsi_path)[len(str(base_path)) + 1:-len(wsi_path.suffix)])\n",
    "            save_path = base_save_path / sub_path\n",
    "\n",
    "            if (save_path / 'Finished.txt').exists():\n",
    "                print('Ignoring {}, as it has already been processed.'.format(wsi_path))\n",
    "            else:\n",
    "                pixels_per_tile_x = int(MICRONS_PER_TILE / float(wsi.properties['openslide.mpp-x']))\n",
    "                pixels_per_tile_y = int(MICRONS_PER_TILE / float(wsi.properties['openslide.mpp-y']))\n",
    "                wsi_paths_to_normalize.append(wsi_path)\n",
    "                save_paths.append(save_path)\n",
    "                save_path.mkdir(parents=True, exist_ok=True)\n",
    "                total_num_tiles += (\n",
    "                        len(range(pixels_per_tile_x, wsi.dimensions[0] - pixels_per_tile_x, pixels_per_tile_x)) *\n",
    "                        len(range(pixels_per_tile_y, wsi.dimensions[1] - pixels_per_tile_y, pixels_per_tile_y)))\n",
    "    except OpenSlideError:\n",
    "        print('Ignoring {}, as it cannot be opened by OpenSlide.'.format(wsi_path))\n",
    "    except KeyError:\n",
    "        print('Ignoring {}, as it does not have a defined microns-per-pixel value'.format(wsi_path))\n",
    "\n",
    "print(f'Masking and normalizing {total_num_tiles} tiles from {len(wsi_paths_to_normalize)} whole slide images.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function, given a whole slide image path and target save path, masks and normalizes all tissue tiles and then saves them into pngs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_and_normalize_wsi(wsi_path, save_path, pbar):\n",
    "    num_tiles_kept = 0\n",
    "    try:\n",
    "        with OpenSlide(str(wsi_path)) as wsi:\n",
    "            pptx = int(MICRONS_PER_TILE / float(wsi.properties['openslide.mpp-x']))\n",
    "            ppty = int(MICRONS_PER_TILE / float(wsi.properties['openslide.mpp-y']))\n",
    "            # Leave out border of image\n",
    "            for x in range(pptx, wsi.dimensions[0] - pptx, pptx):\n",
    "                for y in range(ppty, wsi.dimensions[1] - ppty, ppty):\n",
    "                    tile = wsi.read_region((x, y), level=0, size=(pptx, ppty)).convert('RGB')\n",
    "                    # Mask away all-white and all-black background regions\n",
    "                    mask = tile.convert(mode='L').point(lut=lambda p: 220 > p > 10, mode='1')\n",
    "                    mask = ndimage.binary_fill_holes(mask)\n",
    "                    if np.sum(mask).astype(float) / mask.size > 0.5:\n",
    "                        with warnings.catch_warnings():\n",
    "                            warnings.simplefilter('ignore')\n",
    "                            try:\n",
    "                                # Normalize the tile\n",
    "                                tile = normalizer.transform(np.array(tile))\n",
    "                                tile = Image.fromarray(tile)\n",
    "                                # Resize the image to 224x224\n",
    "                                tile = tile.resize((224, 224), Image.LANCZOS)\n",
    "                                num_tiles_kept += 1\n",
    "                                filename = f'{wsi_path.stem}__x{x}_y{y}_dx{pptx}_dy{ppty}.png'\n",
    "                                tile.save(save_path / filename, format='PNG')\n",
    "                            except np.linalg.LinAlgError:\n",
    "                                pass\n",
    "                    pbar.update()\n",
    "    except OpenSlideError as ex:\n",
    "        print('\\nUnable to process {}:'.format(wsi_path))\n",
    "        print(''.join(traceback.format_exception(etype=type(ex), value=ex, tb=ex.__traceback__)))\n",
    "        shutil.rmtree(save_path)\n",
    "        return 0\n",
    "\n",
    "    with open(save_path / 'Finished.txt', 'w+') as file:\n",
    "        file.write('Kept and processed {} tiles.'.format(num_tiles_kept))\n",
    "    return num_tiles_kept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4172 tiles from patient TCGA-5M-AAT6-01Z-00-DX1 saved to tiled_WSIs/MSIMUT/TCGA-5M-AAT6-01Z-00-DX1.8834C952-14E3-4491-8156-52FC917BB014\n",
      "6951 tiles from patient TCGA-5M-AATE-01Z-00-DX1 saved to tiled_WSIs/MSIMUT/TCGA-5M-AATE-01Z-00-DX1.483FFD2F-61A1-477E-8F94-157383803FC7\n",
      "2051 tiles from patient TCGA-4N-A93T-01Z-00-DX1 saved to tiled_WSIs/MSS/TCGA-4N-A93T-01Z-00-DX1.82E240B1-22C3-46E3-891F-0DCE35C43F8B\n",
      "2960 tiles from patient TCGA-3L-AA1B-01Z-00-DX1 saved to tiled_WSIs/MSS/TCGA-3L-AA1B-01Z-00-DX1.8923A151-A690-40B7-9E5A-FCBEDFC2394F\n",
      "16134 tiles were saved and normalized\n"
     ]
    }
   ],
   "source": [
    "assert len(wsi_paths_to_normalize) == len(save_paths)\n",
    "with tqdm.tqdm(total=total_num_tiles) as pbar:\n",
    "    for wsi_path, save_path in zip(wsi_paths_to_normalize, save_paths):\n",
    "        mask_and_normalize_wsi(wsi_path, save_path, pbar)\n",
    "# Wait a moment for pbar to close\n",
    "time.sleep(0.25)\n",
    "\n",
    "all_save_paths = [p for p in base_save_path.glob('*/*') if p.is_dir()]\n",
    "total_tiles_kept = 0\n",
    "for save_path in all_save_paths:\n",
    "    with open(save_path / 'Finished.txt', 'r') as f:\n",
    "        info = f.readline()\n",
    "    num_tiles_kept = int(re.search('processed ([0-9]+?) tiles', info).group(1))\n",
    "    total_tiles_kept += num_tiles_kept\n",
    "    print(f'{num_tiles_kept} tiles from patient {save_path.stem} saved to {save_path}')\n",
    "print(f'{total_tiles_kept} tiles were saved and normalized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that WSIs have been broken into normalized tiles, we load these images for tumor detection.\n",
    "\n",
    "NB: Make sure to use `with torch.no_grad():` at inference time or there may be memory overflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images for tumor detection...\n",
      "Getting tumor predictions for 16134 tiles in 127 batches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127/127 [00:08<00:00, 15.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9806/16134 tiles contain tumorous tissue\n"
     ]
    }
   ],
   "source": [
    "print('Loading images for tumor detection...')\n",
    "img_dataset = datasets.ImageFolder(\n",
    "    base_save_path,\n",
    "    transforms.Compose([\n",
    "        # Images must be of size 224x224 to be passed to most deep learning vision models\n",
    "        transforms.Resize(224),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")\n",
    "img_dataloader = data.DataLoader(\n",
    "    img_dataset,\n",
    "    batch_size=128,\n",
    "    num_workers=8,\n",
    "    shuffle=False,\n",
    "    pin_memory=True\n",
    ")\n",
    "tumor_detection_model = load_saved_model_for_inference(\n",
    "    'saved_models/resnet18_tumor_detection_exp9.pt',\n",
    "    num_classes=2,\n",
    ").to(DEVICE)\n",
    "\n",
    "print(f'Getting tumor predictions for {len(img_dataset)} tiles in {len(img_dataloader)} batches.')\n",
    "time.sleep(0.25)\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, _ in tqdm.tqdm(img_dataloader):\n",
    "        inputs = inputs.to(DEVICE, non_blocking=True)\n",
    "        outputs = tumor_detection_model(inputs).cpu()\n",
    "        all_preds.append(outputs)\n",
    "all_preds = torch.cat(all_preds, dim=0)\n",
    "time.sleep(0.25)\n",
    "\n",
    "tumorous_tiles = all_preds.argmax(dim=1).flatten()\n",
    "print(f'{tumorous_tiles.sum()}/{len(img_dataset)} tiles contain tumorous tissue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved tile_info_df to \"tiled_WSIs/tile_info.csv\"\n",
      "Saved patient_info_df to \"tiled_WSIs/patient_info.csv\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_25e9a_\" ><caption>Patient info dataframe</caption><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >MSI_status</th>    </tr>    <tr>        <th class=\"index_name level0\" >patient_id</th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_25e9a_level0_row0\" class=\"row_heading level0 row0\" >TCGA-5M-AAT6-01Z-00-DX1.8834C952-14E3-4491-8156-52FC917BB014</th>\n",
       "                        <td id=\"T_25e9a_row0_col0\" class=\"data row0 col0\" >MSI-H</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_25e9a_level0_row1\" class=\"row_heading level0 row1\" >TCGA-5M-AATE-01Z-00-DX1.483FFD2F-61A1-477E-8F94-157383803FC7</th>\n",
       "                        <td id=\"T_25e9a_row1_col0\" class=\"data row1 col0\" >MSI-H</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_25e9a_level0_row2\" class=\"row_heading level0 row2\" >TCGA-3L-AA1B-01Z-00-DX1.8923A151-A690-40B7-9E5A-FCBEDFC2394F</th>\n",
       "                        <td id=\"T_25e9a_row2_col0\" class=\"data row2 col0\" >MSS</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_25e9a_level0_row3\" class=\"row_heading level0 row3\" >TCGA-4N-A93T-01Z-00-DX1.82E240B1-22C3-46E3-891F-0DCE35C43F8B</th>\n",
       "                        <td id=\"T_25e9a_row3_col0\" class=\"data row3 col0\" >MSS</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f592c16d190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_c08bf_\" ><caption>Tile info dataframe example rows</caption><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >tile_id</th>        <th class=\"col_heading level0 col1\" >patient_id</th>        <th class=\"col_heading level0 col2\" >tumor_pred_val</th>        <th class=\"col_heading level0 col3\" >tumor_pred_class</th>        <th class=\"col_heading level0 col4\" >MSI_status</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_c08bf_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_c08bf_row0_col0\" class=\"data row0 col0\" >TCGA-5M-AAT6-01Z-00-DX1.8834C952-14E3-4491-8156-52FC917BB014__x100287_y12156_dx1013_dy1013.png</td>\n",
       "                        <td id=\"T_c08bf_row0_col1\" class=\"data row0 col1\" >TCGA-5M-AAT6-01Z-00-DX1.8834C952-14E3-4491-8156-52FC917BB014</td>\n",
       "                        <td id=\"T_c08bf_row0_col2\" class=\"data row0 col2\" >0.010808</td>\n",
       "                        <td id=\"T_c08bf_row0_col3\" class=\"data row0 col3\" >0</td>\n",
       "                        <td id=\"T_c08bf_row0_col4\" class=\"data row0 col4\" >MSI-H</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c08bf_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_c08bf_row1_col0\" class=\"data row1 col0\" >TCGA-5M-AAT6-01Z-00-DX1.8834C952-14E3-4491-8156-52FC917BB014__x100287_y13169_dx1013_dy1013.png</td>\n",
       "                        <td id=\"T_c08bf_row1_col1\" class=\"data row1 col1\" >TCGA-5M-AAT6-01Z-00-DX1.8834C952-14E3-4491-8156-52FC917BB014</td>\n",
       "                        <td id=\"T_c08bf_row1_col2\" class=\"data row1 col2\" >0.045893</td>\n",
       "                        <td id=\"T_c08bf_row1_col3\" class=\"data row1 col3\" >0</td>\n",
       "                        <td id=\"T_c08bf_row1_col4\" class=\"data row1 col4\" >MSI-H</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c08bf_level0_row2\" class=\"row_heading level0 row2\" >4172</th>\n",
       "                        <td id=\"T_c08bf_row2_col0\" class=\"data row2 col0\" >TCGA-5M-AATE-01Z-00-DX1.483FFD2F-61A1-477E-8F94-157383803FC7__x100287_y10130_dx1013_dy1013.png</td>\n",
       "                        <td id=\"T_c08bf_row2_col1\" class=\"data row2 col1\" >TCGA-5M-AATE-01Z-00-DX1.483FFD2F-61A1-477E-8F94-157383803FC7</td>\n",
       "                        <td id=\"T_c08bf_row2_col2\" class=\"data row2 col2\" >0.999991</td>\n",
       "                        <td id=\"T_c08bf_row2_col3\" class=\"data row2 col3\" >1</td>\n",
       "                        <td id=\"T_c08bf_row2_col4\" class=\"data row2 col4\" >MSI-H</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c08bf_level0_row3\" class=\"row_heading level0 row3\" >4173</th>\n",
       "                        <td id=\"T_c08bf_row3_col0\" class=\"data row3 col0\" >TCGA-5M-AATE-01Z-00-DX1.483FFD2F-61A1-477E-8F94-157383803FC7__x100287_y11143_dx1013_dy1013.png</td>\n",
       "                        <td id=\"T_c08bf_row3_col1\" class=\"data row3 col1\" >TCGA-5M-AATE-01Z-00-DX1.483FFD2F-61A1-477E-8F94-157383803FC7</td>\n",
       "                        <td id=\"T_c08bf_row3_col2\" class=\"data row3 col2\" >0.999997</td>\n",
       "                        <td id=\"T_c08bf_row3_col3\" class=\"data row3 col3\" >1</td>\n",
       "                        <td id=\"T_c08bf_row3_col4\" class=\"data row3 col4\" >MSI-H</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c08bf_level0_row4\" class=\"row_heading level0 row4\" >11123</th>\n",
       "                        <td id=\"T_c08bf_row4_col0\" class=\"data row4 col0\" >TCGA-3L-AA1B-01Z-00-DX1.8923A151-A690-40B7-9E5A-FCBEDFC2394F__x10130_y33429_dx1013_dy1013.png</td>\n",
       "                        <td id=\"T_c08bf_row4_col1\" class=\"data row4 col1\" >TCGA-3L-AA1B-01Z-00-DX1.8923A151-A690-40B7-9E5A-FCBEDFC2394F</td>\n",
       "                        <td id=\"T_c08bf_row4_col2\" class=\"data row4 col2\" >1.000000</td>\n",
       "                        <td id=\"T_c08bf_row4_col3\" class=\"data row4 col3\" >1</td>\n",
       "                        <td id=\"T_c08bf_row4_col4\" class=\"data row4 col4\" >MSS</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c08bf_level0_row5\" class=\"row_heading level0 row5\" >11124</th>\n",
       "                        <td id=\"T_c08bf_row5_col0\" class=\"data row5 col0\" >TCGA-3L-AA1B-01Z-00-DX1.8923A151-A690-40B7-9E5A-FCBEDFC2394F__x10130_y34442_dx1013_dy1013.png</td>\n",
       "                        <td id=\"T_c08bf_row5_col1\" class=\"data row5 col1\" >TCGA-3L-AA1B-01Z-00-DX1.8923A151-A690-40B7-9E5A-FCBEDFC2394F</td>\n",
       "                        <td id=\"T_c08bf_row5_col2\" class=\"data row5 col2\" >1.000000</td>\n",
       "                        <td id=\"T_c08bf_row5_col3\" class=\"data row5 col3\" >1</td>\n",
       "                        <td id=\"T_c08bf_row5_col4\" class=\"data row5 col4\" >MSS</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c08bf_level0_row6\" class=\"row_heading level0 row6\" >14083</th>\n",
       "                        <td id=\"T_c08bf_row6_col0\" class=\"data row6 col0\" >TCGA-4N-A93T-01Z-00-DX1.82E240B1-22C3-46E3-891F-0DCE35C43F8B__x10130_y31403_dx1013_dy1013.png</td>\n",
       "                        <td id=\"T_c08bf_row6_col1\" class=\"data row6 col1\" >TCGA-4N-A93T-01Z-00-DX1.82E240B1-22C3-46E3-891F-0DCE35C43F8B</td>\n",
       "                        <td id=\"T_c08bf_row6_col2\" class=\"data row6 col2\" >0.010911</td>\n",
       "                        <td id=\"T_c08bf_row6_col3\" class=\"data row6 col3\" >0</td>\n",
       "                        <td id=\"T_c08bf_row6_col4\" class=\"data row6 col4\" >MSS</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c08bf_level0_row7\" class=\"row_heading level0 row7\" >14084</th>\n",
       "                        <td id=\"T_c08bf_row7_col0\" class=\"data row7 col0\" >TCGA-4N-A93T-01Z-00-DX1.82E240B1-22C3-46E3-891F-0DCE35C43F8B__x10130_y32416_dx1013_dy1013.png</td>\n",
       "                        <td id=\"T_c08bf_row7_col1\" class=\"data row7 col1\" >TCGA-4N-A93T-01Z-00-DX1.82E240B1-22C3-46E3-891F-0DCE35C43F8B</td>\n",
       "                        <td id=\"T_c08bf_row7_col2\" class=\"data row7 col2\" >0.668856</td>\n",
       "                        <td id=\"T_c08bf_row7_col3\" class=\"data row7 col3\" >1</td>\n",
       "                        <td id=\"T_c08bf_row7_col4\" class=\"data row7 col4\" >MSS</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f590e82bd90>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tile_ids = [Path(s[0]).name for s in img_dataset.samples]\n",
    "patient_ids = [t.split('__')[0] for t in tile_ids]\n",
    "msi_status = [Path(s[0]).parents[1].name for s in img_dataset.samples]\n",
    "tile_info_df = pd.DataFrame({\n",
    "    'tile_id': tile_ids,\n",
    "    'patient_id': patient_ids,\n",
    "    'tumor_pred_val': all_preds[:, 1].numpy(),\n",
    "    'tumor_pred_class': tumorous_tiles.numpy(),\n",
    "    'MSI_status': msi_status,\n",
    "})\n",
    "tile_df_save_path = base_save_path / 'tile_info.csv'\n",
    "tile_info_df.to_csv(tile_df_save_path)\n",
    "print(f'Saved tile_info_df to \"{tile_df_save_path}\"')\n",
    "\n",
    "patient_info_df = pd.DataFrame({\n",
    "    'patient_id': tile_info_df['patient_id'].unique(),\n",
    "    'MSI_status': '',\n",
    "})\n",
    "patient_info_df.set_index('patient_id', inplace=True)\n",
    "for patient_id, msi_status in tile_info_df.groupby('patient_id').MSI_status.unique().iteritems():\n",
    "    # Make sure that MSI status is the same for all tiles within a patient\n",
    "    msi_status, = msi_status\n",
    "    patient_info_df.loc[patient_id] = msi_status\n",
    "patient_df_save_path = base_save_path / 'patient_info.csv'\n",
    "patient_info_df.to_csv(patient_df_save_path)\n",
    "print(f'Saved patient_info_df to \"{patient_df_save_path}\"')\n",
    "\n",
    "display(patient_info_df.style.set_caption('Patient info dataframe'))\n",
    "tile_info_df.groupby('patient_id').head(2).style.set_caption('Tile info dataframe example rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Deep Learning Models\n",
    "\n",
    "The deep learning model pipeline consists of three main steps:\n",
    "1. Data splitting\n",
    "1. Model and data loading\n",
    "1. Training loop\n",
    "    1. Performing inference\n",
    "    1. Calculating loss\n",
    "    1. Backpropagating loss\n",
    "    1. Updating parameters\n",
    "    1. Logging results\n",
    "\n",
    "This notebook will also cover a few other important things to consider:\n",
    "1. Common hardware bottlenecks\n",
    "1. Real-time performance monitoring\n",
    "1. Misc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we split the patients into a train/validation set and a test set.\n",
    "\n",
    "Normally, 10-20% of patients would be assigned to the test set, but since we only have 4 patients in our example dataset, we will perform a 50/50 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_set, test_set = train_test_split(\n",
    "    patient_info_df.index.values,\n",
    "    test_size=0.5,\n",
    "    stratify=patient_info_df['MSI_status'].values\n",
    ")\n",
    "patient_info_df.loc[train_val_set, 'data_subset'] = 'train/validation'\n",
    "patient_info_df.loc[test_set, 'data_subset'] = 'test'\n",
    "tile_info_df = tile_info_df.drop(\n",
    "    columns='data_subset',\n",
    "    errors='ignore'\n",
    ").join(\n",
    "    patient_info_df['data_subset'],\n",
    "    on='patient_id'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we split the tiles from the train/validation patients into a train set and a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_mask = tile_info_df['data_subset'] != 'test'\n",
    "train_set, val_set = train_test_split(\n",
    "    tile_info_df.index.values[train_val_mask],\n",
    "    train_size=0.9,\n",
    "    stratify=tile_info_df['patient_id'].values[train_val_mask]\n",
    ")\n",
    "tile_info_df.loc[train_set, 'data_subset'] = 'train'\n",
    "tile_info_df.loc[val_set, 'data_subset'] = 'validation'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that there are no patients with tiles in both the train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patient_id\n",
       "TCGA-3L-AA1B-01Z-00-DX1.8923A151-A690-40B7-9E5A-FCBEDFC2394F    [train, validation]\n",
       "TCGA-4N-A93T-01Z-00-DX1.82E240B1-22C3-46E3-891F-0DCE35C43F8B                 [test]\n",
       "TCGA-5M-AAT6-01Z-00-DX1.8834C952-14E3-4491-8156-52FC917BB014    [train, validation]\n",
       "TCGA-5M-AATE-01Z-00-DX1.483FFD2F-61A1-477E-8F94-157383803FC7                 [test]\n",
       "Name: data_subset, dtype: object"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tile_info_df.groupby('patient_id')['data_subset'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "print('Testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
