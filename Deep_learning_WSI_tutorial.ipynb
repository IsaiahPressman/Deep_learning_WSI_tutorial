{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ###Outline image here###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "\n",
    "1. [Libraries & Environment](#Libraries-&-Environment)\n",
    "1. [Data Preprocessing](#Data-Preprocessing)\n",
    "    1. Tiling\n",
    "    1. Tumor detection\n",
    "1. [Training Deep Learning Models](#Training-Deep-Learning-Models)\n",
    "    1. Data splitting\n",
    "    1. Model and data loading\n",
    "    1. Common hardware bottlenecks\n",
    "    1. Real-time performance monitoring\n",
    "    1. Misc.\n",
    "1. [Evaluating Performance](#Evaluating-Performance)\n",
    "    1. Patient-level vs. tile-level evaluation\n",
    "    1. AUROC vs. accuracy\n",
    "    1. On improving performance\n",
    "1. [Visualizing Results](#Visualizing-Results)\n",
    "    1. TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries & Environment\n",
    "\n",
    "The base environment that I use can be installed using the create_conda_env.sh bash script.\n",
    "\n",
    "NB: As of June 2021, when installing OpenSlide on Linux, it will not work correctly with some image types due to a broken dependency. (I've noticed this problem for .mrxs images in particular) In order to repair this issue, you can install version 0.40.0 of the pixman library. (Installed automatically in the create_conda_env.sh script) If you notice the slide images look like like the image below, or throw an error when you view them, try this solution.\n",
    "\n",
    "TODO: insert image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from openslide import OpenSlide, OpenSlideError\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "import shutil\n",
    "import tqdm\n",
    "import traceback\n",
    "import warnings\n",
    "\n",
    "# Pytorch imports\n",
    "import torch\n",
    "\n",
    "# Custom imports\n",
    "from library.MacenkoNormalizer import MacenkoNormalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "In order to prepare the WSI images for deep learning training and inference, a number of preprocessing steps must be applied:\n",
    "\n",
    "1. Images are broken into many small tiles (usually 256x256 microns)\n",
    "1. Tiles are filtered to exclude non-tissue background regions\n",
    "1. Tiles are Macenko-normalized\n",
    "1. Tiles are filtered to exclude non-tumorous tissue regions\n",
    "\n",
    "These steps are laid out in example code below. However, when applying this pipeline at scale, the implementation should include multiprocessing and/or CuPy (for Macenko normalization) as these additions provide enormous speedups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masking and normalizing 32853 tiles from 4 whole slide images.\n"
     ]
    }
   ],
   "source": [
    "MICRONS_PER_TILE = 256.\n",
    "\n",
    "# Initialize the Macenko Normalizer\n",
    "reference_img = np.array(Image.open('library/macenko_reference_img.png').convert('RGB'))\n",
    "normalizer = MacenkoNormalizer()\n",
    "normalizer.fit(reference_img)\n",
    "\n",
    "# Find all WSIs and check for errors opening the file or finding the microns-per-pixel values \n",
    "base_path = Path('WSIs')\n",
    "wsi_paths = base_path.rglob('*.svs')\n",
    "save_paths = []\n",
    "wsi_paths_to_normalize = []\n",
    "total_num_tiles = 0\n",
    "for wsi_path in wsi_paths:\n",
    "    try:\n",
    "        with OpenSlide(str(wsi_path)) as wsi:\n",
    "            sub_path = Path(str(wsi_path)[len(str(base_path)) + 1:-len(wsi_path.suffix)])\n",
    "            save_path = Path('tiled_WSIs') / sub_path\n",
    "\n",
    "            if (save_path / 'Finished.txt').exists():\n",
    "                print('Ignoring {}, as it has already been processed.'.format(wsi_path))\n",
    "            else:\n",
    "                pixels_per_tile_x = int(MICRONS_PER_TILE / float(wsi.properties['openslide.mpp-x']))\n",
    "                pixels_per_tile_y = int(MICRONS_PER_TILE / float(wsi.properties['openslide.mpp-y']))\n",
    "                wsi_paths_to_normalize.append(wsi_path)\n",
    "                save_paths.append(save_path)\n",
    "                save_path.mkdir(parents=True, exist_ok=True)\n",
    "                total_num_tiles += (\n",
    "                        len(range(pixels_per_tile_x, wsi.dimensions[0] - pixels_per_tile_x, pixels_per_tile_x)) *\n",
    "                        len(range(pixels_per_tile_y, wsi.dimensions[1] - pixels_per_tile_y, pixels_per_tile_y)))\n",
    "    except OpenSlideError:\n",
    "        print('Ignoring {}, as it cannot be opened by OpenSlide.'.format(wsi_path))\n",
    "    except KeyError:\n",
    "        print('Ignoring {}, as it does not have a defined microns-per-pixel value'.format(wsi_path))\n",
    "\n",
    "print(f'Masking and normalizing {total_num_tiles} tiles from {len(wsi_paths_to_normalize)} whole slide images.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function, given a whole slide image path and target save path, masks and normalizes all tissue tiles and then saves them into pngs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_and_normalize_wsi(wsi_path, save_path, pbar):\n",
    "    num_tiles_kept = 0\n",
    "    try:\n",
    "        with OpenSlide(str(wsi_path)) as wsi:\n",
    "            pptx = int(MICRONS_PER_TILE / float(wsi.properties['openslide.mpp-x']))\n",
    "            ppty = int(MICRONS_PER_TILE / float(wsi.properties['openslide.mpp-y']))\n",
    "            # Leave out border of image\n",
    "            for x in range(pptx, wsi.dimensions[0] - pptx, pptx):\n",
    "                for y in range(ppty, wsi.dimensions[1] - ppty, ppty):\n",
    "                    tile = wsi.read_region((x, y), level=0, size=(pptx, ppty)).convert('RGB')\n",
    "                    # Mask away all-white and all-black background regions\n",
    "                    mask = tile.convert(mode='L').point(lut=lambda p: 220 > p > 10, mode='1')\n",
    "                    mask = ndimage.binary_fill_holes(mask)\n",
    "                    if np.sum(mask).astype(float) / mask.size > 0.5:\n",
    "                        with warnings.catch_warnings():\n",
    "                            warnings.simplefilter('ignore')\n",
    "                            try:\n",
    "                                # Normalize the tile\n",
    "                                tile = normalizer.transform(np.array(tile))\n",
    "                                tile = Image.fromarray(tile)\n",
    "                                # Resize the image to 224x224\n",
    "                                tile = tile.resize((224, 224), Image.LANCZOS)\n",
    "                                num_tiles_kept += 1\n",
    "                                filename = f'{wsi_path.stem}__x{x}_y{y}_dx{pptx}_dy{ppty}.png'\n",
    "                                tile.save(save_path / filename, format='PNG')\n",
    "                            except np.linalg.LinAlgError:\n",
    "                                pass\n",
    "                    pbar.update()\n",
    "    except OpenSlideError as ex:\n",
    "        print('\\nUnable to process {}:'.format(wsi_path))\n",
    "        print(''.join(traceback.format_exception(etype=type(ex), value=ex, tb=ex.__traceback__)))\n",
    "        shutil.rmtree(save_path)\n",
    "        return 0\n",
    "\n",
    "    with open(save_path / 'Finished.txt', 'w+') as file:\n",
    "        file.write('Kept and processed {} tiles.'.format(num_tiles_kept))\n",
    "    return num_tiles_kept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32853/32853 [1:48:05<00:00,  5.07it/s]  \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-13ba6a63e7e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mnum_tiles_kept_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_and_normalize_wsi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwsi_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Wait a moment for pbar to close\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mwsi_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_tiles_kept\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwsi_paths_to_normalize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_tiles_kept_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "assert len(wsi_paths_to_normalize) == len(save_paths)\n",
    "with tqdm.tqdm(total=total_num_tiles) as pbar:\n",
    "    num_tiles_kept_results = []\n",
    "    for wsi_path, save_path in zip(wsi_paths_to_normalize, save_paths):\n",
    "        num_tiles_kept_results.append(mask_and_normalize_wsi(wsi_path, save_path, pbar))\n",
    "# Wait a moment for pbar to close\n",
    "time.sleep(0.25)\n",
    "\n",
    "for wsi_path, save_path, num_tiles_kept in enumerate(zip(wsi_paths_to_normalize, save_paths, num_tiles_kept_results)):\n",
    "    print(f'{num_tiles_kept} tiles from {wsi_path} saved to {save_path}')\n",
    "print(f'{sum(num_tiles_kept)} of {total_num_tiles} were saved and normalized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each image, check for tumor status and then log tumor status to CSV\n",
    "# Then do the same for train/validation/test splitting\n",
    "\"\"\"\n",
    "print('Loading images for tumor detection')\n",
    "img_dataset = datasets.ImageFolder(destination_folder,\n",
    "                                   transforms.Compose([\n",
    "                                       transforms.Resize(224),\n",
    "                                       transforms.ToTensor()\n",
    "                                   ]))\n",
    "img_dataloader = data.DataLoader(img_dataset,\n",
    "                                 batch_size=512,\n",
    "                                 num_workers=8,\n",
    "                                 shuffle=False,\n",
    "                                 pin_memory=True)\n",
    "tumor_detection_model = load_saved_model_for_inference(\n",
    "    '/home/pressmi/Desktop2/Current_selected_models/tumor_detection_1x/resnet18_tumor_detection_exp9.pt',\n",
    "    #'/home/pressmi/Desktop2/Current_selected_models/tumor_detection_2x/exp2_resnet18_acc0.973_loss0.067_rocauc0.999.pt',\n",
    "    num_classes=2,\n",
    ").to(device)\n",
    "\n",
    "print('Getting tumor predictions for {} tiles in {} batches.'.format(\n",
    "    len(img_dataset),\n",
    "    len(img_dataloader)))\n",
    "all_preds = []\n",
    "prog_bar = ProgressBar(len(img_dataloader))\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, _) in enumerate(img_dataloader):\n",
    "        inputs = inputs.to(device, non_blocking=True)\n",
    "        outputs = tumor_detection_model(inputs).cpu()\n",
    "        all_preds.append(outputs)\n",
    "        prog_bar.animate()\n",
    "prog_bar.close()\n",
    "all_preds = torch.cat(all_preds, dim=0)\n",
    "\n",
    "non_tumorous_tiles = (all_preds.argmax(dim=1) == 0).flatten()\n",
    "print('Deleting {} tiles that do not contain tumorous tissue'.format(non_tumorous_tiles.sum()))\n",
    "\n",
    "prog_bar = ProgressBar(non_tumorous_tiles.sum(), print_freq=100)\n",
    "for i, (image_path, _) in enumerate(img_dataset.samples):\n",
    "    if non_tumorous_tiles[i] == True:\n",
    "        os.remove(image_path)\n",
    "        prog_bar.animate()\n",
    "prog_bar.close()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Deep Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "print('Testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
